{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf7c760",
   "metadata": {},
   "source": [
    "## Digit Classification with PyTorch\n",
    " [Data Used](https://www.kaggle.com/c/digit-recognizer/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c848b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import PIL \n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2851a2",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02123439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CLF,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186eafb",
   "metadata": {},
   "source": [
    "### Data to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65a53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample_DataSet(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data = pd.read_csv(filename)\n",
    "        self.features = self.data.columns[1:]\n",
    "        self.target = self.data.columns[0]\n",
    "        is_nan = self.data.isna().values.any()\n",
    "        if is_nan:\n",
    "            self.data = self.data.dropna().reset_index(drop=True)\n",
    "        self.X = torch.from_numpy(self.data[self.features].to_numpy()).type(torch.float32)\n",
    "        self.y = torch.from_numpy(self.data[self.target].to_numpy()).type(torch.long)\n",
    "        self.X = self.X.reshape(42000,1,28,28)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f5280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Sample_DataSet(\"digit-recognizer/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cc05be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42000, 1, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f6d698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.X[0].unsqueeze(dim=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1485f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ecd0385",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766e8a9",
   "metadata": {},
   "source": [
    "### Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16635f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870aaef",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7cb041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for i in (range(epoch)):\n",
    "        # batch-by-batch\n",
    "        for X, y in tqdm(dataloader):\n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            # loss calculation\n",
    "            loss = criterion(output,y)\n",
    "            temp = loss\n",
    "            ##backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#         if i % 15 == 0:\n",
    "        print(\"Loss -> \", loss.item())\n",
    "    print(\"Loss -> \", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af8d7b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1313/1313 [00:13<00:00, 100.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.3869244158267975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1313/1313 [00:13<00:00, 94.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.23793669044971466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1313/1313 [00:14<00:00, 93.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.017408454790711403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1313/1313 [00:13<00:00, 99.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.4173582196235657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1313/1313 [00:14<00:00, 93.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.11674193292856216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1313/1313 [00:13<00:00, 100.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.22493037581443787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1313/1313 [00:12<00:00, 107.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.007482167333364487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1313/1313 [00:11<00:00, 111.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.4095175862312317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1313/1313 [00:11<00:00, 110.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.2089928239583969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1313/1313 [00:12<00:00, 107.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ->  0.06518575549125671\n",
      "Loss ->  0.06518575549125671\n",
      "252.267040387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "train()\n",
    "print(time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c7891",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28c71317",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"digit-recognizer/test.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebb6bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.from_numpy(test[0]).type(torch.float32).reshape(1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb779016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample.unsqueeze(dim=0)).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c69eb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f347ca50af0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample.reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3604c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f74d1e5b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
